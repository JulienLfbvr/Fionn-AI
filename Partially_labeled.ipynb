{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to show the process to fine-tune MESC models on a partially labeled WSI. The newly fine-tuned model can then be used to predict the labels of the unlabeled regions.\n",
    "Data/Export/Temp/json2exp-output/Crop-256/WSI_NAME contains the extracted patches from the WSI_NAME WSI. \n",
    "Data/Partially_labeled/Labeled_data/WSI_NAME.xlsx contains the labeled patches from the WSI_NAME WSI in the format of an excel file formated as follows:\n",
    "filename | M | E | S | C\n",
    "\n",
    "The original MESC models can be found at: mescnn/classification/logs/cnn/holdout/MODEL_NAME\n",
    "the fine-tuned models will be saved at: Data/Partially_labeled/models/WSI_NAME/MODEL_NAME\n",
    "\n",
    "First, the user gives the WSI to the interface. Then the WSI is segmented with our segmentation model. The user then labels some glomerulus patches that will be used to fine-tune the MESC models. \n",
    "(This first part is abstracted in this notebook since the code already exists in the interface)\n",
    "\n",
    "The interface then fine-tunes the MESC models on the labeled patches and saves the new models.\n",
    "\n",
    "Finally, the interface uses the new models to predict the labels of the unlabeled patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "# Dynamically get the root directory of the project\n",
    "#ROOT_DIR = os.path.realpath(__file__) # Not working for notebooks but works for scripts\n",
    "ROOT_DIR = \"/home/ubuntu/M1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>M</th>\n",
       "      <th>E</th>\n",
       "      <th>S</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>glomerulus C1104066 [10884, 59188, 956, 948].jpeg</td>\n",
       "      <td>noM</td>\n",
       "      <td>noE</td>\n",
       "      <td>SGS</td>\n",
       "      <td>noC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>glomerulus C1104066 [142336, 49680, 744, 640]....</td>\n",
       "      <td>noM</td>\n",
       "      <td>noE</td>\n",
       "      <td>GGS</td>\n",
       "      <td>noC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>glomerulus C1104066 [142772, 48280, 1100, 864]...</td>\n",
       "      <td>yesM</td>\n",
       "      <td>noE</td>\n",
       "      <td>NoGS</td>\n",
       "      <td>noC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>glomerulus C1104066 [153544, 5020, 752, 628].jpeg</td>\n",
       "      <td>noM</td>\n",
       "      <td>noE</td>\n",
       "      <td>GGS</td>\n",
       "      <td>noC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>glomerulus C1104066 [28172, 21868, 736, 748].jpeg</td>\n",
       "      <td>noM</td>\n",
       "      <td>noE</td>\n",
       "      <td>SGS</td>\n",
       "      <td>noC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>glomerulus C1104066 [28344, 23428, 748, 708].jpeg</td>\n",
       "      <td>noM</td>\n",
       "      <td>noE</td>\n",
       "      <td>NoGS</td>\n",
       "      <td>noC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>glomerulus C1104066 [33508, 9732, 1396, 604].jpeg</td>\n",
       "      <td>noM</td>\n",
       "      <td>noE</td>\n",
       "      <td>NoGS</td>\n",
       "      <td>noC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>glomerulus C1104066 [8044, 62252, 752, 796].jpeg</td>\n",
       "      <td>noM</td>\n",
       "      <td>noE</td>\n",
       "      <td>GGS</td>\n",
       "      <td>noC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>glomerulus C1104066 [85212, 44372, 936, 880].jpeg</td>\n",
       "      <td>noM</td>\n",
       "      <td>noE</td>\n",
       "      <td>SGS</td>\n",
       "      <td>noC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename     M    E     S    C\n",
       "0  glomerulus C1104066 [10884, 59188, 956, 948].jpeg   noM  noE   SGS  noC\n",
       "1  glomerulus C1104066 [142336, 49680, 744, 640]....   noM  noE   GGS  noC\n",
       "2  glomerulus C1104066 [142772, 48280, 1100, 864]...  yesM  noE  NoGS  noC\n",
       "3  glomerulus C1104066 [153544, 5020, 752, 628].jpeg   noM  noE   GGS  noC\n",
       "4  glomerulus C1104066 [28172, 21868, 736, 748].jpeg   noM  noE   SGS  noC\n",
       "5  glomerulus C1104066 [28344, 23428, 748, 708].jpeg   noM  noE  NoGS  noC\n",
       "6  glomerulus C1104066 [33508, 9732, 1396, 604].jpeg   noM  noE  NoGS  noC\n",
       "7   glomerulus C1104066 [8044, 62252, 752, 796].jpeg   noM  noE   GGS  noC\n",
       "8  glomerulus C1104066 [85212, 44372, 936, 880].jpeg   noM  noE   SGS  noC"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the labeled data from the excel file\n",
    "import pandas as pd\n",
    "\n",
    "labeled_data_dir = \"Data/Partially_labeled/Labeled_data/test.XLSX\"\n",
    "df = pd.read_excel(os.path.join(ROOT_DIR, labeled_data_dir))\n",
    "\n",
    "NUMBER_OF_LABELED_IMAGES = len(df)\n",
    "\n",
    "# Replace the full paths in the filename column by keeping only the image name\n",
    "df['filename'] = df['filename'].apply(lambda x: x.split(\"\\\\\")[-1])\n",
    "\n",
    "mesc_def = {\n",
    "    \"M\": {\n",
    "        0: \"noM\",\n",
    "        1: \"yesM\",\n",
    "    },\n",
    "    \"E\": {\n",
    "        0: \"noE\",\n",
    "        1: \"yesE\"\n",
    "    },\n",
    "    \"S\": {\n",
    "        \"GGS\": \"GGS\",\n",
    "        0: \"NoGS\",\n",
    "        1: \"SGS\"\n",
    "    },\n",
    "    \"C\": {\n",
    "        0: \"noC\",\n",
    "        1: \"yesC\"\n",
    "    }\n",
    "}\n",
    "df[\"M\"] = df[\"M\"].replace(mesc_def[\"M\"])\n",
    "df[\"E\"] = df[\"E\"].replace(mesc_def[\"E\"])\n",
    "df[\"S\"] = df[\"S\"].replace(mesc_def[\"S\"])\n",
    "df[\"C\"] = df[\"C\"].replace(mesc_def[\"C\"])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Set the path to the Crop-256 folder\n",
    "crop256_folder = \"/home/ubuntu/M1/Data/Fine_tuning/cascade_R_50_FPN_1x/Crop-256\"\n",
    "\n",
    "# Set the path to the Data/Classification folder\n",
    "dataset_folder = \"/home/ubuntu/M1/Data/Partially_labeled/Classification\"\n",
    "\n",
    "# If the dataset folder does not exist, create it\n",
    "if not os.path.exists(dataset_folder):\n",
    "    os.makedirs(dataset_folder, exist_ok=True)\n",
    "else: \n",
    "    # If the dataset folder exists, delete all its contents\n",
    "    for file in os.listdir(dataset_folder):\n",
    "        file_path = os.path.join(dataset_folder, file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        \n",
    "wsi = \"C1104066\"\n",
    "\n",
    "for image in os.listdir(os.path.join(crop256_folder, wsi)):\n",
    "    src_path = os.path.join(crop256_folder, wsi, image)\n",
    "    dst_path = os.path.join(dataset_folder, image)\n",
    "    shutil.copy(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the images in the dataset folder into the labeled or unlabeled folders based on the dataframe labels\n",
    "os.makedirs(os.path.join(dataset_folder, \"labeled\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(dataset_folder, \"unlabeled\"), exist_ok=True)\n",
    "\n",
    "for image in os.listdir(dataset_folder):\n",
    "    if os.path.isfile(os.path.join(dataset_folder, image)):\n",
    "        if image in df[\"filename\"].values:\n",
    "            src_path = os.path.join(dataset_folder, image)\n",
    "            dst_path = os.path.join(dataset_folder, \"labeled\", image)\n",
    "            shutil.move(src_path, dst_path)\n",
    "        else:\n",
    "            src_path = os.path.join(dataset_folder, image)\n",
    "            dst_path = os.path.join(dataset_folder, \"unlabeled\", image)\n",
    "            shutil.move(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the train folder\n",
    "train_folder = \"/home/ubuntu/M1/Data/Partially_labeled/Classification/labeled\"\n",
    "possible_labels = [\"noM\", \"yesM\", \"noE\", \"yesE\", \"GGS\", \"NoGS\", \"SGS\", \"noC\", \"yesC\", \"nan_label\"]\n",
    "\n",
    "# Create new subdirectories for the labels in the train and val folders \n",
    "for label in possible_labels:\n",
    "    os.makedirs(os.path.join(train_folder, label), exist_ok=True)\n",
    "    \n",
    "# Iterate over the rows in the df_combined dataframe\n",
    "for index, row in df.iterrows():\n",
    "    # Get the labels of the current row\n",
    "    labels = row[[\"M\", \"E\", \"S\", \"C\"]]\n",
    "    \n",
    "    # Get the name of the current patch\n",
    "    patch_name = row[\"filename\"]\n",
    "    \n",
    "    # Set the source path of the image\n",
    "    source_path = os.path.join(train_folder, patch_name)\n",
    "    \n",
    "    # Set the destination paths of the image\n",
    "    for label in labels:\n",
    "        if label in possible_labels:\n",
    "            dest_path = os.path.join(train_folder, label)\n",
    "            if patch_name in os.listdir(dest_path):\n",
    "                pass\n",
    "            else:\n",
    "                shutil.copy(source_path, dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all the images in the train folder that are not in subdirectories\n",
    "for image in os.listdir(train_folder):\n",
    "    if os.path.isfile(os.path.join(train_folder, image)):\n",
    "        os.remove(os.path.join(train_folder, image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folders for each type of lesion\n",
    "lesion_folders = [\"M\", \"E\", \"S\", \"C\"]\n",
    "dataset_folder = os.path.join(dataset_folder, \"labeled\")\n",
    "for lesion in lesion_folders:\n",
    "    lesion_path = os.path.join(dataset_folder, lesion)\n",
    "    os.makedirs(lesion_path, exist_ok=True)\n",
    "    if lesion == \"M\":\n",
    "        os.makedirs(os.path.join(lesion_path, \"nan_label\"), exist_ok=True)\n",
    "        os.makedirs(os.path.join(lesion_path, \"noM\"), exist_ok=True)\n",
    "        os.makedirs(os.path.join(lesion_path, \"yesM\"), exist_ok=True)\n",
    "    if lesion == \"E\":\n",
    "        os.makedirs(os.path.join(lesion_path, \"noE\"), exist_ok=True)\n",
    "        os.makedirs(os.path.join(lesion_path, \"yesE\"), exist_ok=True)\n",
    "    if lesion == \"S\":\n",
    "        os.makedirs(os.path.join(lesion_path, \"GGS\"), exist_ok=True)\n",
    "        os.makedirs(os.path.join(lesion_path, \"NoGS\"), exist_ok=True)\n",
    "        os.makedirs(os.path.join(lesion_path, \"SGS\"), exist_ok=True)\n",
    "    if lesion == \"C\":\n",
    "        os.makedirs(os.path.join(lesion_path, \"noC\"), exist_ok=True)\n",
    "        os.makedirs(os.path.join(lesion_path, \"yesC\"), exist_ok=True)\n",
    "            \n",
    "# Move the images to the appropriate folders\n",
    "lesion_labels_dict = {\n",
    "    \"M\": [\"nan_label\", \"noM\", \"yesM\"],\n",
    "    \"E\": [\"noE\", \"yesE\"],\n",
    "    \"S\": [\"GGS\", \"NoGS\", \"SGS\"],\n",
    "    \"C\": [\"noC\", \"yesC\"]\n",
    "}\n",
    "                    \n",
    "# Move the images to the appropriate folders                  \n",
    "for lesion in lesion_labels_dict.keys():\n",
    "    for label in lesion_labels_dict[lesion]:\n",
    "        source_folder = os.path.join(dataset_folder, label)\n",
    "        destination_folder = os.path.join(dataset_folder, lesion, label)\n",
    "        for image in os.listdir(source_folder):\n",
    "            source_path = os.path.join(source_folder, image)\n",
    "            destination_path = os.path.join(destination_folder, image)\n",
    "            shutil.move(source_path, destination_path)\n",
    "        # # if the destination folder is empty, delete it\n",
    "        # if len(os.listdir(destination_folder)) == 0:\n",
    "        #     os.rmdir(destination_folder)\n",
    "        os.rmdir(source_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 10**(-5)\n",
    "momentum = 0.8\n",
    "batch_size = 1\n",
    "epochs = 5\n",
    "augmentation = ['HFlip', 'VFlip', 'BtnsCtst']\n",
    "models_dir = os.path.join(ROOT_DIR, \"mescnn/classification/logs/cnn/holdout\")\n",
    "model_name = \"efficientnetv2-m_M_V3.pth\"\n",
    "\n",
    "# Load the M model\n",
    "net = torch.load(os.path.join(models_dir, model_name))\n",
    "\n",
    "# Freeze the net layers except the final layer\n",
    "for param in net.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze the final layer\n",
    "for param in net.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 9\n",
      "    Root location: /home/ubuntu/M1/Data/Partially_labeled/Classification/labeled/M\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "           )\n",
      "['nan_label', 'noM', 'yesM']\n",
      "{'nan_label': 0, 'noM': 1, 'yesM': 2}\n"
     ]
    }
   ],
   "source": [
    "lesion = model_name.split(\"_\")[1]   \n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "data_dir = \"/home/ubuntu/M1/Data/Partially_labeled/Classification/labeled/\" + lesion \n",
    "\n",
    "image_dataset = datasets.ImageFolder(data_dir, data_transforms['train'])\n",
    "dataloader = torch.utils.data.DataLoader(image_dataset, batch_size=batch_size, shuffle=True)\n",
    "dataset_size = len(image_dataset)\n",
    "\n",
    "\n",
    "# Print the data, and each class, as well as the number associated with each class\n",
    "print(image_dataset)\n",
    "print(image_dataset.classes)\n",
    "print(image_dataset.class_to_idx)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "def train_model(model, criterion, optimizer, dataloaders, dataset_sizes, device, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    # Make sure the device is set correctly\n",
    "    model.to(device)\n",
    "\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        # Initially save the current state of the model\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'\\nEpoch {epoch+1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            model.train()  # Set model to training mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders:\n",
    "                inputs.requires_grad = True\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(True):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # # Print outputs and labels to debug the model's predictions\n",
    "                    # if epoch == 0 and phase == 'train':\n",
    "                    #     print(f\"First batch labels and predictions in training: {labels} {preds}\")\n",
    "\n",
    "                    # backward + optimize\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            epoch_loss = running_loss / dataset_sizes\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes\n",
    "            \n",
    "            print(f'Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best Acc: {best_acc:4f}')\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "        \n",
    "    return best_acc, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "----------\n",
      "Loss: 0.5776 Acc: 0.8889\n",
      "\n",
      "Epoch 2\n",
      "----------\n",
      "Loss: 0.6446 Acc: 0.8889\n",
      "\n",
      "Epoch 3\n",
      "----------\n",
      "Loss: 0.5813 Acc: 0.8889\n",
      "\n",
      "Epoch 4\n",
      "----------\n",
      "Loss: 0.5535 Acc: 0.7778\n",
      "\n",
      "Epoch 5\n",
      "----------\n",
      "Loss: 0.4356 Acc: 0.8889\n",
      "Training complete in 0m 8s\n",
      "Best Acc: 0.888889\n",
      "Training accuracy: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "threshold = 0.34042131979695434 \n",
    "acc, model = train_model(net, criterion, optimizer, dataloader, dataset_size, device, num_epochs=epochs)\n",
    "\n",
    "print(f\"Training accuracy: {acc}\")\n",
    "\n",
    "# Save the model\n",
    "fine_tuned_models_dir = os.path.join(ROOT_DIR, \"Data/Partially_labeled/models\", wsi, model_name)\n",
    "os.makedirs(os.path.dirname(fine_tuned_models_dir), exist_ok=True)\n",
    "torch.save(model, fine_tuned_models_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wsi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m unlabeled_folder \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(ROOT_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData/Partially_labeled/Classification/unlabeled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load the model\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(ROOT_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData/Partially_labeled/models\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mwsi\u001b[49m, model_name)\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(model_path)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Set the device\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wsi' is not defined"
     ]
    }
   ],
   "source": [
    "# Using the fine-tuned model make predictions on the unlabeled images \n",
    "unlabeled_folder = os.path.join(ROOT_DIR, \"Data/Partially_labeled/Classification/unlabeled\")\n",
    "\n",
    "# Load the model\n",
    "model_path = os.path.join(ROOT_DIR, \"Data/Partially_labeled/models\", wsi, model_name)\n",
    "model = torch.load(model_path)\n",
    "\n",
    "# Set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set the transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Make predictions on the unlabeled images\n",
    "predictions = []\n",
    "for image in os.listdir(unlabeled_folder):\n",
    "    image_path = os.path.join(unlabeled_folder, image)\n",
    "    img = Image.open(image_path)\n",
    "    img = transform(img)\n",
    "    img = img.unsqueeze(0)\n",
    "    img = img.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(img)\n",
    "        _, preds = torch.max(output, 1)\n",
    "        predictions.append(preds.item())\n",
    "        \n",
    "df_unlabeled = pd.DataFrame({\n",
    "    \"filename\": os.listdir(unlabeled_folder),\n",
    "    \"predicted_label\": predictions\n",
    "})\n",
    "\n",
    "df_unlabeled[\"predicted_label\"] = df_unlabeled[\"predicted_label\"].replace({0:\"nan_label\", 1: \"noM\", 2: \"yesM\"})\n",
    "\n",
    "df_unlabeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>glomerulus C1104066 [10884, 59188, 956, 948].jpeg</td>\n",
       "      <td>noM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>glomerulus C1104066 [142336, 49680, 744, 640]....</td>\n",
       "      <td>noM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>glomerulus C1104066 [142772, 48280, 1100, 864]...</td>\n",
       "      <td>yesM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>glomerulus C1104066 [153544, 5020, 752, 628].jpeg</td>\n",
       "      <td>noM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>glomerulus C1104066 [28172, 21868, 736, 748].jpeg</td>\n",
       "      <td>noM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>glomerulus C1104066 [28344, 23428, 748, 708].jpeg</td>\n",
       "      <td>noM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>glomerulus C1104066 [33508, 9732, 1396, 604].jpeg</td>\n",
       "      <td>noM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>glomerulus C1104066 [8044, 62252, 752, 796].jpeg</td>\n",
       "      <td>noM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>glomerulus C1104066 [85212, 44372, 936, 880].jpeg</td>\n",
       "      <td>noM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>glomerulus C1104066 [8552, 64920, 784, 788].jpeg</td>\n",
       "      <td>noM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>glomerulus C1104066 [88468, 46436, 956, 916].jpeg</td>\n",
       "      <td>yesM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>glomerulus C1104066 [90956, 47096, 908, 960].jpeg</td>\n",
       "      <td>yesM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>glomerulus C1104066 [91180, 45656, 724, 656].jpeg</td>\n",
       "      <td>noM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>glomerulus C1104066 [93432, 46328, 844, 896].jpeg</td>\n",
       "      <td>yesM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>glomerulus C1104066 [94176, 45616, 1124, 812]....</td>\n",
       "      <td>noM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>glomerulus C1104066 [94652, 48228, 636, 644].jpeg</td>\n",
       "      <td>nan_label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>glomerulus C1104066 [95336, 47236, 856, 864].jpeg</td>\n",
       "      <td>noM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             filename          M\n",
       "0   glomerulus C1104066 [10884, 59188, 956, 948].jpeg        noM\n",
       "1   glomerulus C1104066 [142336, 49680, 744, 640]....        noM\n",
       "2   glomerulus C1104066 [142772, 48280, 1100, 864]...       yesM\n",
       "3   glomerulus C1104066 [153544, 5020, 752, 628].jpeg        noM\n",
       "4   glomerulus C1104066 [28172, 21868, 736, 748].jpeg        noM\n",
       "5   glomerulus C1104066 [28344, 23428, 748, 708].jpeg        noM\n",
       "6   glomerulus C1104066 [33508, 9732, 1396, 604].jpeg        noM\n",
       "7    glomerulus C1104066 [8044, 62252, 752, 796].jpeg        noM\n",
       "8   glomerulus C1104066 [85212, 44372, 936, 880].jpeg        noM\n",
       "9    glomerulus C1104066 [8552, 64920, 784, 788].jpeg        noM\n",
       "10  glomerulus C1104066 [88468, 46436, 956, 916].jpeg       yesM\n",
       "11  glomerulus C1104066 [90956, 47096, 908, 960].jpeg       yesM\n",
       "12  glomerulus C1104066 [91180, 45656, 724, 656].jpeg        noM\n",
       "13  glomerulus C1104066 [93432, 46328, 844, 896].jpeg       yesM\n",
       "14  glomerulus C1104066 [94176, 45616, 1124, 812]....        noM\n",
       "15  glomerulus C1104066 [94652, 48228, 636, 644].jpeg  nan_label\n",
       "16  glomerulus C1104066 [95336, 47236, 856, 864].jpeg        noM"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the original labels from the excel file\n",
    "df = pd.read_excel(os.path.join(ROOT_DIR, \"Data/Partially_labeled/Labeled_data/C1104066_JGI.XLSX\"))\n",
    "\n",
    "# Replace the full paths in the filename column by keeping only the image name\n",
    "df['filename'] = df['filename'].apply(lambda x: x.split(\"\\\\\")[-1])\n",
    "\n",
    "# Replace the labels in the dataframe with the corresponding values in the mesc_def dictionary\n",
    "df[\"M\"] = df[\"M\"].replace(mesc_def[\"M\"])\n",
    "\n",
    "# Display the M and filename columns of the dataframe\n",
    "df_labeled = df[[\"filename\", \"M\"]]\n",
    "df_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FionnAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
